import streamlit as st
import google.generativeai as genai
import os

# è¨­å®šç¶²é æ¨™é¡Œ
st.set_page_config(page_title="æˆ‘çš„ AI åŠ©æ‰‹", layout="centered")

st.title("ğŸ¤– æˆ‘çš„ Gemini AI æ‡‰ç”¨")

# è¨­å®š API Key (å„ªå…ˆå¾ Streamlit Secrets è®€å–ï¼Œåœ°ç«¯å‰‡å¾ç’°å¢ƒè®Šæ•¸)
api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")

if not api_key:
    st.error("è«‹åœ¨ Streamlit Secrets æˆ–ç’°å¢ƒè®Šæ•¸ä¸­è¨­å®š GEMINI_API_KEY")
    st.stop()

# åˆå§‹åŒ– Gemini
genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-1.5-flash') # ä½ ä¹Ÿå¯ä»¥æ›æˆ gemini-1.5-pro

# åˆå§‹åŒ–å°è©±ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºä¹‹å‰çš„å°è©±
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ä½¿ç”¨è€…è¼¸å…¥
if prompt := st.chat_input("æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«ä½ çš„å—ï¼Ÿ"):
    # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # å‘¼å« Gemini ç”¢ç”Ÿå›æ‡‰
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # å‚³é€å°è©±ç´€éŒ„çµ¦ Gemini (å¯æ ¹æ“šéœ€æ±‚èª¿æ•´æ˜¯å¦è¦å¸¶æ­·å²ç´€éŒ„)
            response = model.generate_content(prompt)
            full_response = response.text
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")